# 执行层

执行环境每次处理一条输入，该输入取自输入队列中并被导向容器。取决于该条输入以及容器的状态，执行环境更新容器的状态并可以额外添加消息至输出队列，并且更新入口历史（可能连同此前入口消息的响应）。

在给定轮次，执行环境将处理多条输入。**调度器（Scheduler）**会判断哪些输入按何种顺序下将在指定轮次中执行。我们这里不深入讨论过多调度器的细节，而是着重强调一些目标：

-   它必须是*确定性的*，即仅仅取决于给定数据；
-   它应当*公平*的在容器间分布工作量（但对*吞吐*而不是*延迟*进行优化）。
-   每轮的完成的工作量使用*cycles*（详见[章节1.8](#1.8 功能代币)）为计量单位，且应当接近一些预先设定的数量。

另一个执行环境必须处理的任务是，当某子网的容器的生产跨子网消息的速度，比其他子网能够消耗的速度更快的情况。针对该情况，我们实现了一种自我监管的机制用于给生产容器降速。

运行环境还要处理许多其他的资源管理以及簿记任务，但是，所有这些任务都须确定地得到处理。





## 随机磁带

每个子网都拥有**分布式伪随机生成器（以下简称PRG）**的访问权限。如[第3章](#3 链钥密码学I：阈值签名)提及的，伪随机位可以从一个由$(f+1)/n$的BLS阈值签名衍生而来，被称为**随机磁带**。共识协议的每一轮都有一个不同的随机磁带。虽然此BLS签名与共识中使用的随机信标的签名相似（详见[章节5.5](#5.5 随机信标)），其机制却略有不同。

在共识协议中，一旦块高$h$的区块被最终确认，每个诚实节点将释放其在$h+1$块高下随机磁带中的片段。此处隐藏两点含义：

1. 在块高$h$的区块被任何诚实节点副本最终确认前，块高$h$+1的随机磁带是被确保为不可预测的。
2. 在块高$h+1$的区块被任何诚实节点副本确认时，该节点副本一般将拥有所有所需的片段以构建块高$h+1$的随机磁带。

例如在轮次$h$时，子网为获得二进制伪随机数，需要从执行层发起“系统调用”。当块高$h+1$的随机磁带可用时，系统随后就会响应该请求。根据上述的特性（1），我们可以确保在请求发起时，被请求的二进制伪随机数是不可预测的。基于上述的特性（2），一般在下个区块被最终确认时，被请求的二进制伪随机数即可获取。事实上，在当前的实现中，在块高$h$的区块被最终确认时，共识层（详见[章节5](#5 共识层)）将会同时递交块高$h$的区块（其荷载）以及$h+1$的随机磁带来给消息路由层处理。







执行环境是一个处理输入的程序，每次会处理一条输入并将其导向容器。执行环境根据输入和容器的状态来更新容器的状态，并将一些消息添加到输出队列中。同时，它还会记录处理过的输入历史，包括之前输入的响应。

在一个给定的轮次中，执行环境会处理多个输入。调度器会决定在该轮次中哪些输入以何种顺序执行。调度器必须是确定性的，即只取决于给定的数据，并且应该公平地分配工作量（而不是延迟）到不同的容器中。每轮完成的工作量用“cycles”为单位进行计量，应该接近一些预先设定的数量。

执行环境还要处理一种情况，当某个容器的生产速度比其他容器消耗的速度快时，需要采取一种自我监管机制来限制其速度。

除此之外，执行环境还要处理许多其他的资源管理和账务任务，所有这些任务都必须得到确定的处理。

每个子网都有一个分布式伪随机生成器（PRG），可以从一个由BLS阈值签名衍生而来的伪随机位中获取，这被称为“随机磁带”。共识协议的每个轮次都会有一个不同的随机磁带。虽然这个BLS签名与共识中使用的随机信标的签名相似，但机制略有不同。

在共识协议中，一旦一个块高度为h的区块被最终确认，每个诚实节点都会公布其在块高度为h+1的随机磁带中的一段。这里有两个隐含的含义：

1. 在块高度为h的区块被任何诚实节点确认之前，块高度为h+1的随机磁带是不可预测的。
2. 在块高度为h+1的区块被任何诚实节点确认时，该节点通常会拥有构建块高度为h+1的随机磁带所需的所有片段。

例如，在某个轮次h中，子网需要获取二进制伪随机数，需要向执行层发起“系统调用”。当块高度为h+1的随机磁带可用时，系统就会响应该请求。根据上述特性（1），我们可以确保在请求发起时，被请求的二进制伪随机数是不可预测的。根据特性（2），通常在下一个区块被最终









> 你好开发团队，由于代码执行和费用是相关的，开发人员有什么防御措施来防止对他们的容器进行恶意垃圾邮件攻击以耗尽他们的周期？
>
> 另外，ICP 的用户是否也支付周期费用，或者只有 ICP 上的应用程序所有者支付周期费用？

由于代码执行和费用是相关的，开发人员有什么防御措施来防止对他们的容器进行恶意垃圾邮件攻击以耗尽他们的周期？

容器每次执行更新消息时，都必须以 Cycles 为单位进行支付。无论消息是由用户还是由容器发送，都是如此。如果容器没有足够的周期，则它无法执行消息。

这意味着这里有一个明显的攻击场景，其中恶意容器可以向受害容器发送虚假消息以使其耗尽其周期。我们目前有两种类型的缓解措施。

* 当用户向容器发送消息时，它们被称为入口消息。容器可以在 Internet 计算机接受 Ingress 消息进行处理之前检查它。如果容器拒绝该消息，则不会接受该消息进行处理，并且容器无需支付任何费用。有关此 API 的更多详细信息，请参阅[https://sdk.dfinity.org/docs/interface-spec/index.html#system-api-inspect-message 。](https://sdk.dfinity.org/docs/interface-spec/index.html#system-api-inspect-message)
* 当容器向另一个容器发送消息时，它们被称为容器间消息。发送容器必须为请求的传输和最终响应的传输支付费用。查看这些操作的当前费用 ( https://github.com/dfinity/ic/blob/master/rs/config/src/subnet_config.rs#L120 )，如果恶意容器决定攻击受害者容器，它将是一次相当昂贵的攻击。将来，我们计划引入类似的消息检查方案，以进一步保护容器免受其他恶意容器的侵害。由于执行此攻击的成本很高，因此优先级被认为不那么高。

此外，ICP 的用户是否也支付周期费用或仅 ICP 上的应用程序所有者支付周期费用

我们有一个所谓的接收者支付模型。因此，当容器或用户向另一个容器发送消息时，接收容器会为执行付费。

我希望这有帮助！





> 查询 cycles 的费用如何？这些周期也会消耗在查询调用下的恶意攻击中吗？

你好。目前查询 cycles 是“免费的”。我们确实对它们进行了速率限制，因此在一段时间内，给定容器可以使用的指令数量有限，无法为查询提供服务。我们还有边界节点，它限制有多少请求可以命中 IC 上的给定节点。这意味着两件事：

* 目前处理查询不收取任何费用。
* 恶意用户有可能在这个时间段用完您的所有查询预算，而您的诚实用户必须等待下一个时间段才能让他们的查询得到答复。

我们知道目前的情况并不理想，并且确实想解决它。一种想法是也为查询提供类似于检查消息 API 的东西。在这里，我们将在执行查询之前询问容器是否真的要执行查询，并将其计入其预算。

我们也总是对其他想法持开放态度，以了解如何最好地为罐子充电以备查询，以及如何保护罐子免受这种表面积的攻击。



> 请问储存费，比如是每小时扣一次，还是每秒扣一次？我在这里看到成本配置：

该费用在每轮共识中收取一次。每一轮，子网都会就“当前”时间达成一致。所以我们计算自上一轮以来已经过去了多少秒，并相应地收取费用。有关其实现方式，请参见https://github.com/dfinity/ic/blob/master/rs/cycles_account_manager/src/lib.rs#L568 。











## 概述

执行层负责执行单元智能合约。互联网计算机按轮次进行工作，每个轮次都是由共识层对一组消息块达成一致来触发的。在每一轮中，处理复制的子网络状态，一旦达到某个指令限制，执行就会结束。

在一轮开始时，消息块中的消息会被放入到它们相应目标单元的输入队列中。发送到子网络的消息（这些是发送给管理单元的消息）会被放入子网络输入队列。调度器然后对这些消息进行执行排序。

为了优化吞吐量，调度器使用单元级调度。当一个单元被安排执行时，会分配一个可用的CPU核心，然后单元的输入队列中的消息会一个接一个地执行，直到所有消息都被处理完毕。调度器接着选择下一个要执行的单元，继续这个过程，直到达到指令轮次限制或者没有更多的单元可以被调度。每个单元都独立执行，实现并行处理。

为了支付资源使用成本，每个单元都持有一定数量的名为周期（cycles）的代币。执行环境监控资源使用情况，并从单元的余额中扣除相应的周期。



## 调度器

调度器的主要要求是（1）它必须是确定性的（2）它应该在单元之间公平地分配工作负载（3）优化吞吐量优先于延迟。

为了在高负载下保持响应性，单元可以选择预付计算分配。由于单元是单线程的，计算分配是一个CPU核心的一部分，以百分比表示。只有部分子网的计算能力可以被分配，确保为零计算分配的单元（即最大努力单元）取得进展。公平性是指保证单元计算分配（即，一个拥有计算分配A的积压单元在每100轮中至少执行A个完整轮次）并在所有单元之间平均分配剩余容量（“免费计算”）。在具有N个CPU核心（和N × 100计算能力）的确定性状态机中，调度器选择（至少）N个单元执行一个完整的轮次：一个单元在该轮次中要么耗尽指令限制，要么完成所有排队消息的执行。调度算法使用跨轮次累积的积分作为优先级：在每轮开始时，每个单元的计算分配加上免费计算的均匀份额将作为积分添加到每个单元中；优先级队列中的单元被轮询分配到CPU核心（每个前N个单元首先在一个CPU核心上被调度），并从执行完整轮次的每个单元中扣除100积分。



## 消息执行

### 单个单元消息执行

为了安全和可靠性，每个单元都在一个隔离它与其他单元和系统其余部分的沙盒环境中执行。对于执行每个单独的消息，调度器启动托管单元的沙盒进程，并在提供的消息上执行单元。如果沙盒尚不存在，它将编译单元、创建包含Wasm运行时的沙盒并加载编译好的单元代码。然后通过调用运行时来执行消息。每个消息执行可能导致向其他单元发送新消息、修改单元状态的内存页面和/或生成响应。如果响应对应于入口消息，则响应被写入入口历史记录，以便消息发送者可以读取。这些信息与已消耗的指令数量一起返回执行环境以进行记账。

与请求相关的记账信息保存在与请求相关联的调用上下文中。这是一个数据结构，用于跟踪与调用相关的信息，包括它的来源、调用是否已被响应等。对其他单元的调用被记录在调用上下文中，并放置在单元的输出队列中。如果生成了响应，它会被放入入口历史记录（如果它是对入口消息的响应）；调用上下文记录调用已被响应，响应存储在入口历史记录中一定时间。

执行响应类似于执行请求：不同之处在于响应是在触发它的请求的调用上下文中执行的。其他步骤与上述相同。

### 心跳和定时器

单元具有通过设置心跳或定时方法来定期安排任务的能力。在内部，这是通过将消息放入单元特定的任务队列来实现的。当一个单元被安排执行时，调度器以轮询方式选择执行任务还是消息。

### 管理单元消息

互联网计算机上的几种操作被发送到所谓的管理单元并由其执行。这不是一个单元本身：发送给管理单元的消息被引导到相关子网络（见下面的一些示例），并由执行环境拦截并触发它们的执行。

从技术上讲，这是通过两个特定于子网络的队列实现的，一个用于输入消息，另一个用于输出消息。在每轮开始时，这些队列中的消息被优先执行。

### 管理单元

对于其中一些消息，执行完全局限于执行环境。这是管理单元的消息（例如，用于创建、更新设置、启动、停止单元的消息）的情况。发出这些消息时，它们被路由到托管相应单元的子网络（对于单元创建，正确的子网络是在带外决定的），并包含在子网络队列中。在每轮开始时，调度器依次选择并调用执行环境以执行其中的若干消息。执行结果要么是全局复制状态更改（即，创建新单元时），要么是某个单元的本地更改（即，安装代码或更新单元设置）。生成一个响应，例如，表示执行结果的状态，并将其路由回发出单元管理消息的发件人。

### ECDSA消息

其他管理单元消息，如用于 ECDSA 操作的消息，通过涉及互联网计算机软件堆栈的其他组件来执行。这样的消息被路由到一个特殊的子网络（以阈值方式持有 ECDSA 主密钥的子网络），并排队到该子网络的队列。当调度执行时，它们被执行环境捕获，然后涉及共识层，然后引导子网络中的副本生成签名份额，收集份额并构建相关签名，然后将其返回到子网络的输出队列。

### 比特币消息

这些消息被发送到比特币单元；它们被重新路由到托管比特币单元的子网络，并排队到该单元的输入队列。提供的响应直接路由到发出请求的单元。

### 随机数生成

单元可以向管理请求发送请求，从 IC 获取随机位。为了回答这些请求，执行环境使用IC每轮通过数字签名方案生成的随机位。具体来说，每轮IC上的每个子网络都会产生一个 BLS 签名。尽管是确定性生成的，但在产生签名之前，签名的位是不可预测的。从该签名中提取熵，并将其用作伪随机生成器的种子，以生成前一轮中由单元发出的随机请求所需的伪随机位。



## 执行特性和边界

### 快速执行

生活在不同子网络上的 Canister 之间的消息至少需要两轮顺序一致性：一轮是将消息包含在目标子网络的块中的轮次，另一轮是将回复包含在源子网络的块中的轮次。

执行环境为同一子网络托管的 Canister 之间的消息实现了快速跟踪。针对本地子网中的 Canister 的新 Canister 消息，直接排队到目标Canister的输入队列中，并在相同轮次或即将到来的轮次中进行调度。由于新消息的生成和排队完全确定，因此在子网的所有节点上以完全相同的方式发生，所以这个消息不需要通过一致性。

### 确定性时间切片

虽然一轮执行的指令数量是固定的，但任何单个调用的执行可以跨越多个轮次。从技术上讲，这是通过在每轮暂停执行（如果已使用该轮指令），并在 Canister 下次调度时（通常在下一轮）从中断处继续执行来实现的。为了避免 Canister 占用 CPU 核心，对任何单个调用到 Canister 可以使用的最大指令数量进行了限制。如果 Canister 试图执行的指令超过允许的数量，运行时将停止执行；Canister 状态将回滚，而执行所需的周期将被没收。

### 堆增量边界

执行环境还对 Canister 在单轮中可以更改的堆页数设置了限制。这种限制是软性的，也就是说，如果 Canister 超过限制，执行结果仍会提交给状态。然而，只有当 Canister 计划的轮次的堆更改的摊销数量低于限制时，才会执行 Canister 的后续执行。

### cycles 计费

在执行过程中，Canister 消耗诸如 CPU 、网络带宽和内存使用等资源，这些资源需要 cycles 来支付。每个Canister都有一个本地周期账户，用于支付在互联网计算机上的资源使用。需要注意的是，资源成本随子网的复制因子（子网的节点数）而增加。

**执行计费**：在安装时，Canister 中的 Wasm 代码会用于计算智能合约消息的执行指令的代码。这允许为每个执行的消息确定性地计算精确的 cycles 数量。

在消息被调度执行之前，会从 Canister 的 cycles 余额中扣除相应于运行最大指令数量的 cycles 数。执行继续——仪器返回执行的总指令数量。如果这超过了允许的最大指令数，Canister 陷阱并丧失已提取的 cycles 。如果 Canister 执行的指令少于最大可用指令，则未使用的指令对应的周期将返回到 Canister 余额。

**调用计费**：Canister在向其他Canister发送消息时需要支付带宽消耗。消息传输的成本与发送的消息大小成正比，因此是有上限的，因为互联网计算机上的消息本身大小有上限。

当Canister向另一个Canister发起调用时，执行环境会从调用者的账户中扣除 cycles ，以支付传出调用的成本和被调用者将发送的潜在回复的成本。由于回复的大小事先未知，扣除的 cycles 覆盖了最大大小回复，如果回复较短，多余的 cycles 将返回给调用 Canister 。

**内存计费**：Canister 使用的内存（包括其 Wasm 代码和状态）也需要 cycles 支付。执行环境跟踪多个轮次的内存使用情况，并定期为此使用情况收费。

**冻结阈值**：为防止 Canister 突然耗尽周期并丢失所有存储数据，互联网计算机允许 Canister 所有者定义所谓的冻结阈值。当 Canister 周期账户低于此阈值时，Canister 停止执行任何新计算，即拒绝所有传入请求。它仍然执行回复（每当发出请求时，都会为相应回复的执行预留 cycles ）并仅支付内存消耗。

此外，如果提取 cycles 会使 cycles 账户低于冻结阈值，则不会提取用于执行或消息传输的 cycles 。在这种情况下，Canister 不会尝试执行相应操作。

